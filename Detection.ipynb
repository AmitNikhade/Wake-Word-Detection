{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jJW1M1-yL6kV"
   },
   "source": [
    "# Real Time Wake Word Detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "fp6kI_r7L4Pf",
    "outputId": "4ac257a1-3cd0-4489-b858-937e4a25bfd8"
   },
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import pyaudio\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "from queue import Queue\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters (from WWD_data.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sms5zs8FL4Lj"
   },
   "outputs": [],
   "source": [
    "T_x = 5511\n",
    "T_y = 1375\n",
    "n_freq = 101\n",
    "\n",
    "fs = 44100\n",
    "chunk_duration = 0.5 # each read window\n",
    "feed_duration = 10   # the total feed length\n",
    "chunk_samples = int(fs * chunk_duration)\n",
    "feed_samples = int(fs * feed_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Silence (16 bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_data = None\n",
    "# arr_data = []\n",
    "\n",
    "# def callback(in_data, frame_count, time_info, status):\n",
    "#     global audio_data\n",
    "#     audio_data = np.frombuffer(in_data, dtype='int16')\n",
    "#     ave = np.abs(audio_data).mean()\n",
    "#     print(ave)\n",
    "#     arr_data.append(ave)\n",
    "#     return (in_data, pyaudio.paContinue)\n",
    "\n",
    "# stream = pyaudio.PyAudio().open(\n",
    "#     format=pyaudio.paInt16,\n",
    "#     channels=1,\n",
    "#     rate=fs,\n",
    "#     input=True,\n",
    "#     frames_per_buffer=chunk_samples,\n",
    "#     input_device_index=0,\n",
    "#     stream_callback=callback)\n",
    "\n",
    "# stream.start_stream()\n",
    "# time.sleep(5.1)\n",
    "# stream.stop_stream()\n",
    "# stream.close()\n",
    "\n",
    "# print(\"total average: \", sum(arr_data)/len(arr_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plt_spectrogram(audio_data):\n",
    "#     \"\"\"\n",
    "#     Plot and calculate spectrogram for audio data\n",
    "#     \"\"\"\n",
    "#     n_fft = 200 # window length (length of fast fourier transform)\n",
    "#     fs = 8000 # number of samples per time (sample frequency)\n",
    "#     n_overlap = 120 # overlap length of windows\n",
    "#     n_channels = audio_data.ndim # number of dimensions\n",
    "#     if n_channels == 1:\n",
    "#         pxx, _, _, _ = plt.specgram(audio_data, n_fft, fs, noverlap = n_overlap)\n",
    "#     elif n_channels == 2: # multi-channel audio\n",
    "#         pxx, _, _, _ = plt.specgram(audio_data[:,0], n_fft, fs, noverlap = n_overlap)\n",
    "#     return pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt_spectrogram(audio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 469
    },
    "colab_type": "code",
    "id": "DQS8rguXL4IY",
    "outputId": "f474ee07-cfbf-44cb-ac70-3a355897efbe"
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "from keras.models import load_model\n",
    "model = load_model(\"./model/final_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up audio detection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TE2CDqYYL4E1"
   },
   "outputs": [],
   "source": [
    "def detect_wake_word(spec_data):\n",
    "    \"\"\"\n",
    "    Predict location of wake word\n",
    "    note: spec has shape (n_freqs, T_x)\n",
    "    \"\"\"\n",
    "    spec_data = spec_data.swapaxes(0, 1)\n",
    "    spec_data = np.expand_dims(spec_data, axis=0)\n",
    "    preds = model.predict(spec_data)\n",
    "    preds = preds.reshape(-1)\n",
    "    return preds # flatten\n",
    "\n",
    "def is_new_detection(preds, chunk_duration, feed_duration, threshold=0.8):\n",
    "    \"\"\"\n",
    "    Detects whether a new wake word has been detected in the chunk\n",
    "    \"\"\"\n",
    "    # mask predications and extract the wanted chunk\n",
    "    preds = preds > threshold\n",
    "    chunk_pred_samples = int(len(preds) * chunk_duration/feed_duration)\n",
    "    chunk_preds = preds[-chunk_pred_samples:]\n",
    "    \n",
    "    base = chunk_preds[0] # init base/level\n",
    "    for pred in chunk_preds:\n",
    "        if pred > base:\n",
    "            return True\n",
    "        else:\n",
    "            base = pred\n",
    "    return False\n",
    "\n",
    "def get_spectrogram(audio_data):\n",
    "    \"\"\"\n",
    "    Plot and calculate spectrogram for audio data.\n",
    "    \"\"\"\n",
    "    n_fft = 200 # Length of each window segment\n",
    "    fs = 8000 # Sampling frequencies\n",
    "    n_overlap = 120 # Overlap between windows\n",
    "    n_channels = audio_data.ndim\n",
    "    if n_channels == 1:\n",
    "        pxx, _, _ = mlab.specgram(audio_data, n_fft, fs, noverlap = n_overlap)\n",
    "    elif n_channels == 2:\n",
    "        pxx, _, _ = mlab.specgram(audio_data[:,0], n_fft, fs, noverlap = n_overlap)\n",
    "    return pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XzExjSxL369"
   },
   "outputs": [],
   "source": [
    "def callback(in_data, frame_count, time_info, status):\n",
    "    global run, timeout, data, threshold\n",
    "    if time.time() > timeout:\n",
    "        run = False\n",
    "    # read new data from buffer and process it\n",
    "    new_data = np.frombuffer(in_data, dtype='int16')\n",
    "    if np.abs(new_data).mean() < threshold:\n",
    "        print('0', end='')\n",
    "        return (in_data, pyaudio.paContinue)\n",
    "    else:\n",
    "        print('1', end='')\n",
    "        # add the new data if not silent\n",
    "        data = np.append(data, new_data)\n",
    "        if len(data) > feed_samples:\n",
    "            data = data[-feed_samples:]\n",
    "            que.put(data)\n",
    "        return (in_data, pyaudio.paContinue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gHj0FBw2L3uv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000000000000011000011000110000111█"
     ]
    }
   ],
   "source": [
    "# define and start stream\n",
    "que = Queue() # enables communication between audio callback and main thread\n",
    "run = True\n",
    "threshold = 100\n",
    "timeout = time.time() + 60 # half a minute\n",
    "data = np.zeros(feed_samples, dtype='int16') # data buffer for input\n",
    "\n",
    "run = True\n",
    "\n",
    "stream = pyaudio.PyAudio().open(format=pyaudio.paInt16,\n",
    "                                channels=1,\n",
    "                                rate=fs,\n",
    "                                input=True,\n",
    "                                frames_per_buffer=chunk_samples,\n",
    "                                input_device_index=0,\n",
    "                                stream_callback=callback)\n",
    "stream.start_stream()\n",
    "\n",
    "try:\n",
    "    while run:\n",
    "        data = que.get()\n",
    "        spec = get_spectrogram(data)\n",
    "        preds = detect_wake_word(spec)\n",
    "        new_wake = is_new_detection(preds, chunk_duration, feed_duration)\n",
    "        if new_wake:\n",
    "            print('█', end='')\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "except (KeyboardInterrupt, SystemExit):\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    timeout = time.time()\n",
    "    run = False\n",
    "\n",
    "stream.stop_stream()\n",
    "stream.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "real-time-detection.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
